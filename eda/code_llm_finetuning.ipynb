{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f44884d-38c7-4656-a45e-b1b96afe7c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Handle imports\n",
    "##############################################################################\n",
    "from docling.document_converter import DocumentConverter\n",
    "import traceback\n",
    "from collections.abc import Iterable\n",
    "import os\n",
    "import pypdfium2 as pdfium\n",
    "import re\n",
    "import json\n",
    "import jsonlines\n",
    "import uuid\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "from deepeval import assert_test\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import GEval, AnswerRelevancyMetric\n",
    "from deepeval import evaluate\n",
    "from huggingface_hub import snapshot_download, login, HfApi\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import xml.etree.ElementTree as etree\n",
    "from longdocfactscore.ldfacts import LongDocFACTScore\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, interleave_datasets\n",
    "nltk.download('punkt_tab')\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from transformers import DataCollatorForLanguageModeling, TrainingArguments\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from peft import LoraConfig\n",
    "from transformers import EarlyStoppingCallback\n",
    "import torch\n",
    "import optuna\n",
    "import traceback\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2df5d2-b6ab-41a2-bdcc-398fd85c45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Set up variables\n",
    "##############################################################################\n",
    "SOURCE_DIR=\"source_docs\"\n",
    "SOURCE_DIR_CHUNKED=\"source_docs_chunked\"\n",
    "MARKDOWN_DIR=\"markdown\"\n",
    "MARKDOWN_URI_PREFIX=\"https://raw.githubusercontent.com/agapebondservant/code-generation-capstone/refs/heads/main/eda/resources\"\n",
    "REPORT_DIR=\"reports\"\n",
    "OUTPUT_DIR=\"output\"\n",
    "INVALID_DIR=\"invalid\"\n",
    "ERROR_DIR=\"error\" \n",
    "MODEL_DIR=\"models\"\n",
    "MODEL_IDS = [\"ibm-granite/granite-8b-code-instruct-4k\",\"ibm-granite/granite-8b-code-base-128k\"]\n",
    "DEVICE=\"cuda\"\n",
    "DATASET_REPO=f\"{os.getenv('HF_USERNAME')}/codegen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "146bed40-2949-4e17-8bc1-745b44393567",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Set up object instances\n",
    "##############################################################################\n",
    "\n",
    "data_generator_llm = ChatOpenAI(\n",
    "    model=os.getenv(\"DATA_GENERATOR_MODEL_ID\"), # os.getenv('QWEN25CODER_MODEL_ID'),\n",
    "    api_key=os.getenv('OPENROUTER_TOKEN'),\n",
    "    base_url=os.getenv('OPENROUTER_API_BASE'),\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "class DataGeneratorLLM(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model\n",
    "    ):\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        return chat_model.invoke(prompt).content\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        res = await chat_model.ainvoke(prompt)\n",
    "        return res.content\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Custom Data Generator LLM (GPT-OSS)\"\n",
    "\n",
    "evaluator_llm = DataGeneratorLLM(data_generator_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa50c10-3803-4a75-b143-4efc12f75988",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# PROMPTS AND PROMPT TYPES\n",
    "##############################################################################\n",
    "\n",
    "summary_prompt = \"\"\"\n",
    "Your task is to analyze this code snippet and provide an explanation of the code.\n",
    "    \n",
    "Instructions:\n",
    "1. Provide a concise explanation that summarizes the purpose of the code without getting into too many specific technical details.\n",
    "2. If the provided snippet does not appear to be a code snippet, indicate that this is not valid code.\n",
    "3. Also exclude any details that link the requirements to a specific programming language or framework.\n",
    "\"\"\"\n",
    "\n",
    "topics_prompt = \"\"\"\n",
    "Use the provided summary to analyze this code snippet and generate a list of programming topics that are related to the code.\n",
    "    \n",
    "Instructions:\n",
    "1. Provide a short list of topics that you can identify.\n",
    "2. If the provided snippet does not appear to be a code snippet, indicate that this is not valid code.\n",
    "\"\"\"\n",
    "\n",
    "components_prompt = \"\"\"\n",
    "Your task is to analyze this code snippet and generate a specification of all the JSP relevant components you can find.\n",
    "\n",
    "Instructions:\n",
    "1. Include only relevant components.\n",
    "3. If the provided snippet does not appear to be a code snippet, indicate that this is not valid code.\n",
    "\"\"\"\n",
    "\n",
    "domain_prompt = \"\"\"\n",
    "Your task is to analyze this code snippet and generate an outline of the domain model associated with this code.\n",
    "    \n",
    "Instructions:\n",
    "1. Avoid getting into too many specific technical details. Simply provide a domain model of the code.\n",
    "2. If the provided snippet does not appear to be a code snippet, indicate that this is not valid code.\n",
    "3. Include the current state of the domain objects based on information extracted from the code.\n",
    "\"\"\"\n",
    "\n",
    "keywords_prompt = \"\"\"\n",
    "Your task is to analyze this code snippet and generate a list of keywords that are associated with the code.\n",
    "    \n",
    "Instructions:\n",
    "1. Provide a short list of keywords.\n",
    "2. If the provided snippet does not appear to be a code snippet, indicate that this is not valid code.\n",
    "\"\"\"\n",
    "\n",
    "functional_requirements_prompt = \"\"\"\n",
    "Use the provided summary to analyze this code snippet and generate a list of programming topics that are related to the code.\n",
    "    \n",
    "Instructions:\n",
    "1. Provide a short list of topics that you can identify.\n",
    "2. If the provided snippet does not appear to be a code snippet, indicate that this is not valid code.\n",
    "\"\"\"\n",
    "\n",
    "business_requirements_prompt = \"\"\"\n",
    "Use the provided summary to generate an outline of sample business requirements that might be connected to the code.\n",
    "\n",
    "Instructions:\n",
    "1. Provide a short list of relevant requirements. Do not include requirements that are not related to the code.\n",
    "2. If the provided snippet does not appear to be a code snippet, indicate that this is not valid code.\n",
    "\"\"\"\n",
    "\n",
    "prompts = {\n",
    "\n",
    "    \"functional_requirements\": {\n",
    "        \n",
    "        \"prompt\": functional_requirements_prompt, \n",
    "\n",
    "        \"title\": \"Functional Requirements\",\n",
    "    },\n",
    "    \"business_requirements\": {\n",
    "        \n",
    "        \"prompt\": business_requirements_prompt, \n",
    "\n",
    "        \"title\": \"Business Requirements\",\n",
    "    },\n",
    "    \"topics\": {\n",
    "        \n",
    "        \"prompt\": topics_prompt, \n",
    "\n",
    "        \"title\": \"Components\",\n",
    "    },\n",
    "    \"components\": {\n",
    "        \n",
    "        \"prompt\": components_prompt,\n",
    "\n",
    "        \"title\": \"Topics\",\n",
    "    },\n",
    "    \"keywords\": {\n",
    "        \n",
    "        \"prompt\": keywords_prompt,\n",
    "\n",
    "        \"title\": \"Keywords\",\n",
    "    },\n",
    "    \"summary\": {\n",
    "        \n",
    "        \"prompt\": summary_prompt,\n",
    "\n",
    "        \"title\": \"Summary\",\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "prompts_with_dependencies = {\n",
    "    \"topics\": \"summary\",\n",
    "    \n",
    "    \"business_requirements\": \"summary\",\n",
    "    \n",
    "    \"functional_requirements\": \"summary\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a16f1a-8c36-4e70-b4f6-fb7ac24e54b0",
   "metadata": {},
   "source": [
    "### Download candidate models\n",
    "The following candidate models will be downloaded:\n",
    "- ibm-granite/granite-8b-code-instruct-4k\n",
    "- ibm-granite/granite-8b-code-base-128k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ee5b701-d7ff-404c-87e4-c0893efd1601",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# UTILITY METHODS\n",
    "##############################################################################\n",
    "\n",
    "def download_models(repo_id):\n",
    "    try:\n",
    "        ##############################################################################\n",
    "        # Save the model\n",
    "        ##############################################################################\n",
    "        local_dir = snapshot_download(repo_id=repo_id, cache_dir=MODEL_DIR)\n",
    "        \n",
    "        print(f\"Model {repo_id} downloaded to: {local_dir}\")\n",
    "\n",
    "        ##############################################################################\n",
    "        # Save the tokenizer\n",
    "        ##############################################################################\n",
    "        tokenizer = AutoTokenizer.from_pretrained(repo_id)\n",
    "\n",
    "        if tokenizer.pad_token is None:\n",
    "            \n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        tokenizer.save_pretrained(local_dir)\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "    \n",
    "        print(f\"Error downloading model {repo_id}: {e}\")\n",
    "\n",
    "def upload_models(repo_id, model_dir):\n",
    "\n",
    "    try:\n",
    "    \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "        \n",
    "        model = AutoModelForCausalLM.from_pretrained(model_dir, \n",
    "                                                     trust_remote_code=True,\n",
    "                                                     device_map=DEVICE)\n",
    "    \n",
    "        api = HfApi()\n",
    "    \n",
    "        api.create_repo(repo_id=repo_id, repo_type=\"model\")\n",
    "    \n",
    "        api.upload_folder(\n",
    "            folder_path=model_dir,\n",
    "            \n",
    "            repo_id=repo_id,\n",
    "            \n",
    "            repo_type=\"model\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "    \n",
    "        print(f\"Error uploading model {repo_id} from directory {model_dir}: {e}\")\n",
    "\n",
    "def build_datasets(dataset_name):\n",
    "\n",
    "    final_datasets = []\n",
    "\n",
    "    def process_summary_to_text(example, code_type=\"\"):\n",
    "        \n",
    "        example[\"text\"], example[\"completion\"], example[\"code_type\"] = example[\"summary\"], example[code_type], [code_type]*len(example[\"code\"])\n",
    "        \n",
    "        return example\n",
    "\n",
    "    def process_code_to_text(example, code_type=\"\"):\n",
    "        example[\"text\"], example[\"completion\"], example[\"code_type\"] = example[\"code\"], example[code_type], [code_type]*len(example[\"code\"])\n",
    "        \n",
    "        return example\n",
    "    \n",
    "    train_dataset = load_dataset(dataset_name, split=\"train\")\n",
    "\n",
    "    test_dataset = load_dataset(dataset_name, split=\"test\")\n",
    "\n",
    "    for dataset in [train_dataset, test_dataset]:\n",
    "\n",
    "        datasets = []\n",
    "\n",
    "        code_types = [c for c, obj in prompts.items() if c not in ['code']]\n",
    "        \n",
    "        for code_type in code_types:\n",
    "\n",
    "            if code_type in prompts_with_dependencies:\n",
    "\n",
    "                datasets.append(dataset.map(process_summary_to_text, batched=True, fn_kwargs={\"code_type\": code_type}))\n",
    "            \n",
    "            else:\n",
    "\n",
    "                datasets.append(dataset.map(process_code_to_text, batched=True, fn_kwargs={\"code_type\": code_type}))\n",
    "\n",
    "        final_datasets.append(interleave_datasets(datasets))\n",
    "\n",
    "    return final_datasets\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47d90482-ea95-4402-86c6-02a51d1bf92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Code Formatting Helper Function\n",
    "##############################################################################\n",
    "def code_text_formatter(example):\n",
    "\n",
    "    _code = example['code']\n",
    "    \n",
    "    _summary = example['summary']\n",
    "\n",
    "    _code_type = example[\"code_type\"]\n",
    "\n",
    "    _text = example['text']\n",
    "\n",
    "    _prompt = prompts[_code_type][\"prompt\"]\n",
    "\n",
    "    _title = prompts[_code_type][\"title\"]\n",
    "\n",
    "    ######################################\n",
    "    # Code-Summary pair\n",
    "    ######################################\n",
    "    if _code_type in prompts_with_dependencies:\n",
    "        text = f\"\"\"\n",
    "        <|assistant|>\n",
    "        {_prompt}\n",
    "        Summary:\n",
    "        {_summary}\n",
    "        <|assistant|>\n",
    "        {_title}:\n",
    "        {_text}<|endoftext|>\n",
    "        \"\"\"\n",
    "\n",
    "        return text\n",
    "\n",
    "    #######################\n",
    "    # Code-Text pair\n",
    "    #######################\n",
    "    else:\n",
    "        text = f\"\"\"\n",
    "        <|system|>\n",
    "        You are a helpful assistant.\n",
    "        {_prompt}\n",
    "        Code to analyze:\n",
    "        <|user|>\n",
    "        {_code}\n",
    "        <|assistant|>\n",
    "        {_title}:\n",
    "        {_text}<|endoftext|>\n",
    "        \"\"\"\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cc0e7b1-0171-41f3-97a1-21fd1726d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# PIPELINES\n",
    "##############################################################################\n",
    "def peft_finetuning_pipeline(dataset_name, use_dora=False):\n",
    "    \"\"\"\n",
    "    Executes the LoRA pipeline.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        [os.makedirs(dirname, exist_ok=True) for dirname in [\n",
    "            MODEL_DIR\n",
    "        ]]\n",
    "    \n",
    "        ##############################################################################\n",
    "        # Early Stopping Callback\n",
    "        ##############################################################################\n",
    "        early_stopping_callback = EarlyStoppingCallback(\n",
    "            early_stopping_patience=3,\n",
    "            \n",
    "            early_stopping_threshold=0.001,\n",
    "        )   \n",
    "    \n",
    "        ##############################################################################\n",
    "        # Load models to finetune\n",
    "        ##############################################################################\n",
    "        for model_id in MODEL_IDS:\n",
    "    \n",
    "            print(f\"Start finetuning {model_id}...\")\n",
    "\n",
    "            base_model_dir = model_id.replace(\"/\",\"_\")\n",
    "\n",
    "            [os.makedirs(dirname, exist_ok=True) for dirname in [\n",
    "                f\"{MODEL_DIR}/{base_model_dir}/experiment\",\n",
    "                f\"{MODEL_DIR}/{base_model_dir}/final\",\n",
    "                f\"{MODEL_DIR}/{base_model_dir}/model\",\n",
    "            ]]\n",
    "    \n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                \n",
    "                model_id,\n",
    "                \n",
    "                device_map=\"auto\",\n",
    "\n",
    "                trust_remote_code=True,\n",
    "            )\n",
    "    \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    \n",
    "            if tokenizer.pad_token is None:\n",
    "                \n",
    "                tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "            train_dataset, test_dataset = build_datasets(dataset_name)\n",
    "        \n",
    "            ##############################################################################\n",
    "            # Data collator\n",
    "            ##############################################################################\n",
    "            collator = DataCollatorForLanguageModeling(\n",
    "                \n",
    "                tokenizer=tokenizer,\n",
    "                \n",
    "                mlm=False,\n",
    "            )\n",
    "            \n",
    "            ##############################################################################\n",
    "            # Objective Function for Hyperparameter Tuning\n",
    "            ##############################################################################\n",
    "            def objective(trial):\n",
    "\n",
    "                ##############################################################################\n",
    "                # Hyperparameters\n",
    "                ##############################################################################\n",
    "\n",
    "                learning_rate = trial.suggest_float(\n",
    "                    \"learning_rate\", 1e-5, 1e-4, log=True\n",
    "                )\n",
    "                \n",
    "                per_device_train_batch_size = trial.suggest_categorical(\n",
    "                    \"per_device_train_batch_size\", [16, 32]\n",
    "                )\n",
    "                \n",
    "                r = trial.suggest_categorical(\n",
    "                    \"r\", [8, 16, 32]\n",
    "                )\n",
    "                \n",
    "                lora_alpha = trial.suggest_categorical(\n",
    "                    \"lora_alpha\", [16, 32, 64]\n",
    "                )\n",
    "                \n",
    "                lora_dropout = trial.suggest_categorical(\n",
    "                    \"lora_dropout\", [0.05, 0.1]\n",
    "                )\n",
    "                \n",
    "    \n",
    "                ##############################################################################\n",
    "                # LoRA / DORA Configuration\n",
    "                ##############################################################################\n",
    "            \n",
    "                lora_config = LoraConfig(\n",
    "                    r=r, \n",
    "                    \n",
    "                    lora_alpha=lora_alpha,\n",
    "                    \n",
    "                    target_modules=None,\n",
    "                    \n",
    "                    lora_dropout=lora_dropout,\n",
    "                    \n",
    "                    bias=\"none\",\n",
    "            \n",
    "                    use_dora=use_dora,\n",
    "                )\n",
    "\n",
    "                ##############################################################################\n",
    "                # Training Arguments / SFTConfig\n",
    "                ##############################################################################\n",
    "                training_args = SFTConfig(\n",
    "                    \n",
    "                    output_dir=f\"{MODEL_DIR}/{base_model_dir}/experiment\",\n",
    "                    \n",
    "                    learning_rate=learning_rate,\n",
    "                    \n",
    "                    per_device_train_batch_size=per_device_train_batch_size,\n",
    "                    \n",
    "                    per_device_eval_batch_size=per_device_train_batch_size,\n",
    "                    \n",
    "                    num_train_epochs=10,\n",
    "                    \n",
    "                    logging_steps=100,\n",
    "                    \n",
    "                    fp16=True,\n",
    "                    \n",
    "                    report_to=\"none\",\n",
    "                    \n",
    "                    eval_strategy=\"epoch\",  \n",
    "                    \n",
    "                    save_strategy=\"epoch\",   \n",
    "                    \n",
    "                    load_best_model_at_end=True,  \n",
    "                \n",
    "                    metric_for_best_model=\"eval_loss\", \n",
    "                    \n",
    "                    greater_is_better=False,   \n",
    "                    \n",
    "                    max_length=4096,\n",
    "                    \n",
    "                    packing=False,    \n",
    "                \n",
    "                    seed=42,\n",
    "                )\n",
    "        \n",
    "                ##############################################################################\n",
    "                # Supervised Finetuning Trainer\n",
    "                ##############################################################################\n",
    "            \n",
    "                trainer = SFTTrainer(\n",
    "                    \n",
    "                    model=model,\n",
    "                    \n",
    "                    args=training_args,\n",
    "                    \n",
    "                    train_dataset=train_dataset,\n",
    "                    \n",
    "                    eval_dataset=test_dataset,\n",
    "                    \n",
    "                    peft_config = lora_config,\n",
    "                    \n",
    "                    formatting_func = code_text_formatter,\n",
    "                    \n",
    "                    data_collator = collator,\n",
    "                    \n",
    "                    callbacks=[early_stopping_callback],\n",
    "                )\n",
    "\n",
    "                trainer.train()\n",
    "\n",
    "                return trainer.state.best_metric\n",
    "                \n",
    "\n",
    "            ##############################################################################\n",
    "            # Perform Hyperparameter Search\n",
    "            ##############################################################################\\\n",
    "\n",
    "            study = optuna.create_study(direction=\"minimize\") # Minimize loss\n",
    "            \n",
    "            study.optimize(objective, n_trials=10)\n",
    "    \n",
    "            final_lora_config = LoraConfig(\n",
    "                r=study.best_params[\"r\"], \n",
    "                \n",
    "                lora_alpha=study.best_params[\"lora_alpha\"],\n",
    "                \n",
    "                target_modules=None,\n",
    "                \n",
    "                lora_dropout=study.best_params[\"lora_dropout\"],\n",
    "                \n",
    "                bias=\"none\",\n",
    "        \n",
    "                use_dora=use_dora,\n",
    "            )\n",
    "            \n",
    "            final_training_args = SFTConfig(\n",
    "                output_dir=f\"{MODEL_DIR}/{base_model_dir}/final\",\n",
    "            \n",
    "                learning_rate=study.best_params[\"learning_rate\"],\n",
    "                \n",
    "                per_device_train_batch_size=study.best_params[\"per_device_train_batch_size\"],\n",
    "                \n",
    "                per_device_eval_batch_size=study.best_params[\"per_device_train_batch_size\"],\n",
    "                \n",
    "                num_train_epochs=10,\n",
    "                \n",
    "                logging_steps=100,\n",
    "                \n",
    "                fp16=True,\n",
    "                \n",
    "                report_to=\"none\",\n",
    "                \n",
    "                eval_strategy=\"epoch\",  \n",
    "                \n",
    "                save_strategy=\"epoch\",   \n",
    "                \n",
    "                load_best_model_at_end=True,  \n",
    "            \n",
    "                metric_for_best_model=\"eval_loss\", \n",
    "                \n",
    "                greater_is_better=False,   \n",
    "                \n",
    "                max_length=4096,\n",
    "                \n",
    "                packing=False,    \n",
    "            \n",
    "                seed=42,\n",
    "            )\n",
    "            \n",
    "            final_trainer = SFTTrainer(\n",
    "                \n",
    "                model=model,\n",
    "                \n",
    "                args=final_training_args,\n",
    "                \n",
    "                train_dataset=train_dataset,\n",
    "                \n",
    "                eval_dataset=test_dataset,\n",
    "                \n",
    "                peft_config = final_lora_config,\n",
    "                \n",
    "                formatting_func = code_text_formatter,\n",
    "                \n",
    "                data_collator = collator,\n",
    "                \n",
    "                callbacks=[early_stopping_callback],\n",
    "            )\n",
    "            \n",
    "            ##############################################################################\n",
    "            # Start finetuning!\n",
    "            ##############################################################################\n",
    "            final_trainer.train()\n",
    "    \n",
    "            ##############################################################################\n",
    "            # Save snapshot and push to HuggingFace Hub\n",
    "            ##############################################################################\n",
    "\n",
    "            try:\n",
    "            \n",
    "                model.save_pretrained(f\"{MODEL_DIR}/{base_model_dir}/model\")\n",
    "                \n",
    "                tokenizer.save_pretrained(f\"{MODEL_DIR}/{base_model_dir}/model\")\n",
    "\n",
    "                published_model_id = model_id.partition(\"/\")[2] or model_id\n",
    "\n",
    "                model.push_to_hub(published_model_id)\n",
    "\n",
    "            except Exception as e:\n",
    "\n",
    "                print(f\"Error saving and pushing to HuggingFace: {e}\")\n",
    "        \n",
    "                traceback.print_exc()\n",
    "            \n",
    "    except Exception as e:\n",
    "\n",
    "        print(f\"Error running PEFT pipeline: {e}\")\n",
    "\n",
    "        traceback.print_exc()\n",
    "\n",
    "def lora_finetuning_pipeline(dataset_name):\n",
    "    \"\"\"\n",
    "    Executes the LoRA pipeline.\n",
    "    \"\"\"\n",
    "    return peft_finetuning_pipeline(dataset_name, use_dora=False)\n",
    "        \n",
    "def dora_finetuning_pipeline(dataset_name):\n",
    "    \"\"\"\n",
    "    Executes the DORA pipeline.\n",
    "    \"\"\"\n",
    "    return peft_finetuning_pipeline(dataset_name, use_dora=True)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c31ca-9551-46d8-807b-64284e9f1cbd",
   "metadata": {},
   "source": [
    "### Run the pipeline\n",
    "Execute the pipelines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4b5148e-7f72-402f-a194-7655fd4e5a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start finetuning ibm-granite/granite-8b-code-instruct-4k...\n",
      "Error running PEFT pipeline: unsupported operand type(s) for /: 'str' and 'str'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_23611/1653455611.py\", line 32, in peft_finetuning_pipeline\n",
      "    MODEL_DIR/base_model_dir/\"experiment\",\n",
      "    ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "TypeError: unsupported operand type(s) for /: 'str' and 'str'\n"
     ]
    }
   ],
   "source": [
    "lora_finetuning_pipeline(f\"{os.getenv('HF_USERNAME')}/jsp-code-to-text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b366d3-90a2-4ff1-8501-dc963a96a2df",
   "metadata": {},
   "source": [
    "### Evaluate the candidate models\n",
    "Evaluate the candidate models using the following metrics / bechmarks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c7fba3e-e2fe-40df-89bc-3c307ed54414",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Perform data\n",
    "###################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8641f134-8345-42c3-b7d7-173d35777470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
