{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f44884d-38c7-4656-a45e-b1b96afe7c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Handle imports\n",
    "##############################################################################\n",
    "from docling.document_converter import DocumentConverter\n",
    "import traceback\n",
    "from collections.abc import Iterable\n",
    "import os\n",
    "import pypdfium2 as pdfium\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "from deepeval import assert_test\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import GEval, AnswerRelevancyMetric\n",
    "from deepeval import evaluate\n",
    "import xml.etree.ElementTree as etree\n",
    "from longdocfactscore.ldfacts import LongDocFACTScore\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2df5d2-b6ab-41a2-bdcc-398fd85c45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Set up variables\n",
    "##############################################################################\n",
    "SOURCE_DIR=\"source_docs\"\n",
    "SOURCE_DIR_CHUNKED=\"source_docs_chunked\"\n",
    "MARKDOWN_DIR=\"markdown\"\n",
    "MARKDOWN_URI_PREFIX=\"https://raw.githubusercontent.com/agapebondservant/code-generation-capstone/refs/heads/main/eda/resources\"\n",
    "REPORT_DIR=\"reports\"\n",
    "OUTPUT_DIR=\"output\"\n",
    "INVALID_DIR=\"invalid\"\n",
    "ERROR_DIR=\"error\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "146bed40-2949-4e17-8bc1-745b44393567",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Set up object instances\n",
    "##############################################################################\n",
    "\n",
    "data_generator_llm = ChatOpenAI(\n",
    "    model=os.getenv(\"DATA_GENERATOR_MODEL_ID\"), # os.getenv('QWEN25CODER_MODEL_ID'),\n",
    "    api_key=os.getenv('OPENROUTER_TOKEN'),\n",
    "    base_url=os.getenv('OPENROUTER_API_BASE'),\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "class DataGeneratorLLM(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model\n",
    "    ):\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        return chat_model.invoke(prompt).content\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        res = await chat_model.ainvoke(prompt)\n",
    "        return res.content\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Custom Data Generator LLM (GPT-OSS)\"\n",
    "\n",
    "evaluator_llm = DataGeneratorLLM(data_generator_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e4423d-bbd4-472f-97ff-32bfe4a91ebb",
   "metadata": {},
   "source": [
    "### Data Conversion\n",
    "The following pipeline is executed:\n",
    "- A set of pdf files is collected from the source directory.\n",
    "- The pdf files are split up into individual chapters.\n",
    "- Each chapter is converted into markdown using a smart OCR tool (<a href=\"https://github.com/docling-project/docling\" target=\"_blank\">Docling</a>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29731f33-1b6f-4690-8a6c-d9e36a74c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# DATA EXTRACTION\n",
    "##############################################################################\n",
    "def get_chapter_ranges(sourcefilename, do_print=True):\n",
    "    \"\"\"\n",
    "    Returns a list of (beginPage, endPage) ranges for chunks that represent chapters in the given pdf.\n",
    "    \"\"\"\n",
    "    print(\"Getting chapter ranges...\\n\")\n",
    "    \n",
    "    pdf = pdfium.PdfDocument(sourcefilename)\n",
    "    \n",
    "    chapters = []\n",
    "    \n",
    "    begin, end = None, None\n",
    "    \n",
    "    for item in pdf.get_toc():\n",
    "        boundary = None\n",
    "        \n",
    "        if item.page_index and ((item.n_kids == 0 and item.level < 2) or item.level == 2):\n",
    "            if begin is not None:\n",
    "                \n",
    "                end = item.page_index - 1\n",
    "                \n",
    "                boundary = [begin, max(begin, end)]\n",
    "                \n",
    "                chapters.append([item.title, boundary])\n",
    "                \n",
    "            begin = item.page_index\n",
    "            \n",
    "    return chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "038181f1-285c-418e-b1c3-7c15de763328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_chapters(sourcefilename, targetfilename, pagerange):\n",
    "    \"\"\"\n",
    "    Splits the pdf into chapters using the provided page ranges.\n",
    "    Returns the name of the new pdf chunk.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        source_pdf = pdfium.PdfDocument(sourcefilename)\n",
    "        \n",
    "        new_pdf = pdfium.PdfDocument.new()\n",
    "    \n",
    "        print(f\"Saving chapter...{targetfilename}, Pages {pagerange[0]} to {pagerange[1]}\")\n",
    "        \n",
    "        new_page_index = new_pdf.import_pages(source_pdf, pages=list(range(pagerange[0], pagerange[1]+1)))\n",
    "        \n",
    "        new_pdf.save(targetfilename)\n",
    "        \n",
    "        source_pdf.close()\n",
    "        \n",
    "        new_pdf.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {targetfilename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a6df146-3924-42a5-8da0-395711453d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_markdown(pdffile, markdownfile):\n",
    "    \"\"\"\n",
    "    Converts the given PDF file into a Markdown file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        converter = DocumentConverter()\n",
    "        \n",
    "        result = converter.convert(pdffile)\n",
    "        \n",
    "        markdown_output = result.document.export_to_markdown()\n",
    "    \n",
    "        with open(markdownfile, \"w\") as file:\n",
    "            file.write(markdown_output)\n",
    "    \n",
    "        print(f\"{markdownfile} generated.\")\n",
    "\n",
    "        return markdown_output\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {markdownfile}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91a690d5-76f8-4f47-9c59-f65bab2fbb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_snippets(content):\n",
    "    \"\"\"\n",
    "    Parses out code sections of the markdown file.\n",
    "    \"\"\"\n",
    "    \n",
    "    code_snippets = re.findall(r'```([^`]+)```', content, re.DOTALL)\n",
    "\n",
    "    return code_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a6bde69-ce36-4ddf-8c13-bcc41dbe5f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(data, reportname, header=None):\n",
    "    \"\"\"\n",
    "    Writes the given data to a report file with the given name.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(reportname, \"a\") as file:\n",
    "\n",
    "            if header:\n",
    "                file.write(header + \"\\n\")\n",
    "            \n",
    "            if isinstance(data, Iterable):\n",
    "                \n",
    "                file.write(\"\\n\".join([str(d) for d in data]))\n",
    "            else:\n",
    "                \n",
    "                file.write(data)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating report {reportname}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b78f354-d14f-45fb-bd1e-283b0af90a50",
   "metadata": {},
   "source": [
    "### Generate code-text pairs\n",
    "The following code-text pairs will be generated:\n",
    "- Code-to-markdown\n",
    "- Code-to-requirements\n",
    "- Code-to-topics\n",
    "- Code-to-components (JavaBeans, Controllers, Views, Custom Tags)\n",
    "- Code-to-domain\n",
    "- Code-to-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29e020dc-80ae-4f52-9fba-1f5f09969b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Prompts\n",
    "###################################\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "    You are an expert software engineer with extensive experience in developing JSP applications.\n",
    "    {code_instructions}\n",
    "    \n",
    "    Code to analyze:\n",
    "    \"\"\"\n",
    "\n",
    "CODE_TO_REQUIREMENTS_INSTRUCTIONS_PROMPT = \"\"\"\n",
    "    Your task is to analyze this code snippet and generate an outline of functional requirements that might be connected to the code.\n",
    "    \n",
    "    Instructions:\n",
    "    1. **Provide a short list of relevant requirements.** Do not include requirements that are not related to the code.\n",
    "    2. **Format your response clearly and concisely** using a numbered list.\n",
    "    3. If the provided snippet does not appear to be a code snippet, say THIS IS NOT CODE.\n",
    "\"\"\"\n",
    "\n",
    "CODE_TO_TOPICS_INSTRUCTIONS_PROMPT = \"\"\"\n",
    "    Your task is to analyze this code snippet and generate a list of general programming topics that are related to the code.\n",
    "    \n",
    "    Instructions:\n",
    "    1. **Provide a short list of topics that you can identify.**\n",
    "    2. **Format your response clearly and concisely** using a numbered list.\n",
    "    3. If the provided snippet does not appear to be a code snippet, say THIS IS NOT CODE.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "CODE_TO_COMPONENTS_INSTRUCTIONS_PROMPT = \"\"\"\n",
    "    Your task is to analyze this code snippet and generate an outline of all the components you can find, \n",
    "    such as Model Components or JavaBeans, Controllers, Views, JSTL tags, Scriplets, etc.\n",
    "    \n",
    "    Instructions:\n",
    "    1. **Provide an overview of all the components that you can find.**\n",
    "    2. **Format your response clearly and concisely** using a numbered list.\n",
    "    3. If the provided snippet does not appear to be a code snippet, say THIS IS NOT CODE.\n",
    "\"\"\"\n",
    "\n",
    "CODE_TO_KEYWORDS_INSTRUCTIONS_PROMPT = \"\"\"\n",
    "    Your task is to analyze this code snippet and generate a list of keywords that are associated with the code.\n",
    "    \n",
    "    Instructions:\n",
    "    1. **Provide a short list of one-word keywords.**\n",
    "    2. **Format your response clearly and concisely** using a comma-delimited list.\n",
    "    3. If the provided snippet does not appear to be a code snippet, say THIS IS NOT CODE.\n",
    "\"\"\"\n",
    "\n",
    "CODE_TO_SUMMARY_INSTRUCTIONS_PROMPT = \"\"\"\n",
    "    Your task is to analyze this code snippet and provide a summary of the code.\n",
    "    \n",
    "    Instructions:\n",
    "    1.  **Provide a concise summary, including the potential business purpose and use cases for the code.**\n",
    "    2.  **Format your response clearly and concisely** using a numbered list.\n",
    "    3. If the provided snippet does not appear to be a code snippet, say THIS IS NOT CODE.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d655f5d-c373-488a-8e5c-94707c87aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Validation and Evaluation functions\n",
    "###################################\n",
    "def get_validation_issues(item):\n",
    "    \"\"\"\n",
    "    Returns a list of validation issues associated with this item,\n",
    "    or an empty list if no validation issues were found.\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    #########################\n",
    "    # 1. Check if valid json\n",
    "    #########################\n",
    "    try:\n",
    "        \n",
    "        json.dumps(item)\n",
    "        \n",
    "    except Exception as e:\n",
    "        \n",
    "        issues.append(f\"{str(item)},Invalid JSON\")\n",
    "\n",
    "    #########################\n",
    "    # 2. Check missing values\n",
    "    #########################\n",
    "    if None in item.values():\n",
    "\n",
    "        issues.append(f\"{json.dumps(item)},Missing Values\")\n",
    "\n",
    "    #########################\n",
    "    # 3. Check valid JSP code\n",
    "    #########################\n",
    "    if \"THIS IS NOT CODE\" in item.values():\n",
    "\n",
    "        issues.append(f\"{json.dumps(item)},Invalid Code\")\n",
    "\n",
    "    return issues\n",
    "        \n",
    "\n",
    "def evaluate_dataset_entry(item):\n",
    "    \"\"\"\n",
    "    Evaluates the given item with automated metrics.\n",
    "    The following metrics are evaluated:\n",
    "    1. For Coherence: G-Eval (LLM-as-Judge)\n",
    "    2. For Relevancy: G-Eval (LLM-as-Judge)\n",
    "    \"\"\"\n",
    "\n",
    "    evaluations = {\n",
    "        \"coherence\": {},\n",
    "        \"relevancy\": {},\n",
    "    }\n",
    "\n",
    "    ##################################################\n",
    "    # 1. Measuring Coherence metric with G-eval\n",
    "    ##################################################\n",
    "\n",
    "    input_prompts = [ \n",
    "        (\"requirements\", CODE_TO_REQUIREMENTS_INSTRUCTIONS_PROMPT),\n",
    "        \n",
    "        (\"topics\", CODE_TO_TOPICS_INSTRUCTIONS_PROMPT),\n",
    "        \n",
    "        (\"components\", CODE_TO_COMPONENTS_INSTRUCTIONS_PROMPT),\n",
    "        \n",
    "        (\"keywords\", CODE_TO_KEYWORDS_INSTRUCTIONS_PROMPT),\n",
    "        \n",
    "        (\"summary\", CODE_TO_SUMMARY_INSTRUCTIONS_PROMPT),\n",
    "    ]\n",
    "\n",
    "    for code_type, prompt in input_prompts:\n",
    "    \n",
    "        test_case = LLMTestCase(\n",
    "            \n",
    "            input=f\"{prompt}\\nCode:{str(item[\"code\"])}\",\n",
    "            \n",
    "            actual_output=f\"{code_type.capitalize()}:{item[code_type]}\",\n",
    "        ) \n",
    "    \n",
    "        coherence_metric = GEval(\n",
    "            name=\"Coherence\",\n",
    "            \n",
    "            criteria=\"Determine if the actual output flows logically from the given input.\",\n",
    "            \n",
    "            evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "            \n",
    "            threshold=0.5,\n",
    "            \n",
    "            strict_mode=False,\n",
    "            \n",
    "            verbose_mode=False, \n",
    "            \n",
    "            model=evaluator_llm\n",
    "        )\n",
    "    \n",
    "        relevancy_metric = AnswerRelevancyMetric(\n",
    "            include_reason=True,\n",
    "            \n",
    "            model=evaluator_llm,\n",
    "            \n",
    "            threshold=0.5,\n",
    "            \n",
    "            strict_mode=False,\n",
    "    \n",
    "            verbose_mode=False, \n",
    "        )\n",
    "        \n",
    "        coherence_metric.measure(test_case)\n",
    "        \n",
    "        evaluations[\"coherence\"][code_type] = {\"score\": coherence_metric.score, \"reason\": coherence_metric.reason}\n",
    "\n",
    "        relevancy_metric.measure(test_case)\n",
    "        \n",
    "        evaluations[\"relevancy\"][code_type] = {\"score\": relevancy_metric.score, \"reason\": relevancy_metric.reason}\n",
    "\n",
    "    return evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6c40888-8cd3-4a62-8275-6a7666f72f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Utility functions\n",
    "###################################\n",
    "\n",
    "code_types = [\n",
    "    \"requirements\",\n",
    "    \"topics\",\n",
    "    \"components\",\n",
    "    \"keywords\",\n",
    "    \"summary\",\n",
    "]\n",
    "\n",
    "def llm_tool(inputs):\n",
    "    \"\"\"\n",
    "    Invokes LLM with given input.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(\n",
    "        SYSTEM_PROMPT\n",
    "    )\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            system_message_prompt,\n",
    "            HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    chain = prompt | data_generator_llm\n",
    "         \n",
    "    responses = chain.batch(inputs)\n",
    "    \n",
    "    return responses\n",
    "\n",
    "def build_code_completion_pair(snippet, doc, metadata={}, outputfilename=\"data\"):\n",
    "    \"\"\"\n",
    "    Generates code-completion pairs from the given doc.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        item = {\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \n",
    "            \"metadata\": metadata,\n",
    "            \n",
    "            \"code\": snippet,\n",
    "            \n",
    "            \"section\": doc.page_content,\n",
    "        }\n",
    "    \n",
    "        inputs = [\n",
    "            {\n",
    "                \"input\": snippet, \n",
    "                 \"code_instructions\": CODE_TO_REQUIREMENTS_INSTRUCTIONS_PROMPT,\n",
    "            },\n",
    "            {\n",
    "                \"input\": snippet, \n",
    "                 \"code_instructions\": CODE_TO_TOPICS_INSTRUCTIONS_PROMPT,\n",
    "            },\n",
    "            {\n",
    "                \"input\": snippet, \n",
    "                 \"code_instructions\": CODE_TO_COMPONENTS_INSTRUCTIONS_PROMPT,\n",
    "            },\n",
    "            {\n",
    "                \"input\": snippet, \n",
    "                 \"code_instructions\": CODE_TO_KEYWORDS_INSTRUCTIONS_PROMPT,\n",
    "            },\n",
    "            {\n",
    "                \"input\": snippet, \n",
    "                 \"code_instructions\": CODE_TO_SUMMARY_INSTRUCTIONS_PROMPT,\n",
    "            }\n",
    "        ]\n",
    "         \n",
    "        responses = llm_tool(inputs)\n",
    "\n",
    "        for idx, response in enumerate(responses):\n",
    "\n",
    "            code_type = code_types[idx]\n",
    "            \n",
    "            item[code_type] = response.content\n",
    "\n",
    "        validation_issues = get_validation_issues(item)\n",
    "\n",
    "        if validation_issues:\n",
    "\n",
    "            with open(f\"{INVALID_DIR}/{outputfilename}.txt\", 'a') as f:\n",
    "                \n",
    "                f.writelines(validation_issues)\n",
    "        \n",
    "        else:\n",
    "\n",
    "            item[\"metadata\"][\"evaluations\"] = evaluate_dataset_entry(item)\n",
    "\n",
    "            with open(f\"{OUTPUT_DIR}/{outputfilename}.jsonl\", 'a') as f:\n",
    "            \n",
    "                json_line = json.dumps(item)\n",
    "            \n",
    "                f.write(json_line + '\\n')     \n",
    "        \n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"Error writing snippet {snippet}: {e}\")\n",
    "        \n",
    "        traceback.print_exc() \n",
    "\n",
    "        with open(f\"{ERROR_DIR}/{outputfilename}.txt\", 'a') as f:\n",
    "            \n",
    "            f.write(snippet + ',' + e + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49d4e5cd-1143-4670-9b0c-2a94ef094115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_markdown_sections(markdownfilename, outputfilename, content=None):\n",
    "\n",
    "    try:\n",
    "    \n",
    "        if content is None:\n",
    "            \n",
    "            with open(markdownfilename, mode=\"r\") as f: \n",
    "                content = f.read()\n",
    "                \n",
    "        headers_to_split = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"),(\"###\", \"Header 3\")]\n",
    "        \n",
    "        text_splitter = MarkdownHeaderTextSplitter(headers_to_split, strip_headers=False)\n",
    "        \n",
    "        splits = text_splitter.split_text(content)\n",
    "            \n",
    "        for i, split in enumerate(splits):\n",
    "            \n",
    "            sections = get_code_snippets(split.page_content)\n",
    "        \n",
    "            if sections:\n",
    "\n",
    "                print(f\"Processing split {i} in {markdownfilename}...\")\n",
    "\n",
    "                for section in sections:\n",
    "        \n",
    "                    build_code_completion_pair(section, \n",
    "                                               \n",
    "                                               split, \n",
    "                                               \n",
    "                                               metadata={\"source\": f\"{MARKDOWN_URI_PREFIX}/{markdownfilename}\"} | split.metadata, \n",
    "                                               \n",
    "                                               outputfilename=outputfilename)\n",
    "            else:\n",
    "                \n",
    "                print(f\"Skipping split {i} in {markdownfilename} - no code snippets found...\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"Error handling markdown section {markdownfilename}: {e}\")\n",
    "        \n",
    "        traceback.print_exc() \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c31ca-9551-46d8-807b-64284e9f1cbd",
   "metadata": {},
   "source": [
    "### Run the pipeline\n",
    "Execute the pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cc0e7b1-0171-41f3-97a1-21fd1726d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extraction_pipeline():\n",
    "    \"\"\"\n",
    "    Executes the full data extraction pipeline.\n",
    "    \"\"\"\n",
    "    [os.makedirs(dirname, exist_ok=True) for dirname in [\n",
    "        SOURCE_DIR, \n",
    "        SOURCE_DIR_CHUNKED, \n",
    "        MARKDOWN_DIR, \n",
    "        REPORT_DIR, \n",
    "        OUTPUT_DIR,\n",
    "        INVALID_DIR,\n",
    "        ERROR_DIR\n",
    "    ]]\n",
    "    \n",
    "    source_files = [f for f in os.listdir(SOURCE_DIR) if \".pdf\" in f]\n",
    "\n",
    "    output_file=f\"data{datetime.now().strftime('%Y%m%d%H%M')}\"\n",
    "    \n",
    "    for file in source_files:\n",
    "\n",
    "        try:\n",
    "        \n",
    "            chapters = get_chapter_ranges(f\"{SOURCE_DIR}/{file}\", do_print=False)\n",
    "    \n",
    "            generate_report(chapters, f\"{REPORT_DIR}/chapters.txt\", \"Title,Page Range\")\n",
    "            \n",
    "            for idx, [title, _range] in enumerate(chapters):\n",
    "                \n",
    "                pdf = f\"{SOURCE_DIR_CHUNKED}/{idx}_{file}\"\n",
    "                \n",
    "                md = f\"{MARKDOWN_DIR}/{idx}_{file.replace('.pdf', '.md')}\"\n",
    "                \n",
    "                # split_chapters(f\"{SOURCE_DIR}/{file}\", pdf, _range)\n",
    "                \n",
    "                # content = convert_to_markdown(pdf, md)\n",
    "    \n",
    "                split_markdown_sections(md, output_file)\n",
    "\n",
    "        except Exception as e:\n",
    "        \n",
    "            print(f\"Error handling {SOURCE_DIR}/{file}: {e}\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4b5148e-7f72-402f-a194-7655fd4e5a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using Custom Data Generator LLM (GPT-OSS), strict=Fa…</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[38;2;55;65;81m(using Custom Data Generator LLM (GPT-OSS), strict=Fa…\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 11:22:46,768 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f213003014944529a5a7a59ad7f0d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 11:22:47,384 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:22:47,886 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b37d63c3eb4062aecb50fbd70e4e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 11:22:50,873 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:22:51,811 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:22:53,022 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa050dc8d394432bcf8b2f1216792b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 11:22:53,633 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:22:54,090 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2df783c746d4d3380edce21a8edd68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 11:22:54,723 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:22:56,852 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:22:58,067 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing split 5 in markdown/86_vdoc.pub_core-servlets-and-javaserver-pages.md...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 11:22:58,593 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:22:58,631 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:22:58,670 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:22:58,734 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:22:58,751 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff315c687444380bef803de9cae845e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 11:23:00,937 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:23:01,576 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32481d33c528411b93659e32eba6057a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 11:23:03,268 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:23:05,886 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:23:07,003 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a1b1c682304820ba8a9b1c252cd838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 11:23:07,321 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:23:07,990 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03db753943aa4c4395be21fab5ee6ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 11:23:09,959 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:23:10,892 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:23:11,733 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44909c131e04968a4238c0ab917253b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "2025-10-28 11:23:12,962 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-28 11:23:13,670 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "data_extraction_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
